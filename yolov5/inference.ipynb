{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboostcv16\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import SGD, Adam, AdamW, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import val  # for end-of-epoch mAP\n",
    "from models.experimental import attempt_load\n",
    "from models.yolo import Model\n",
    "from utils.autoanchor import check_anchors\n",
    "from utils.autobatch import check_train_batch_size\n",
    "from utils.callbacks import Callbacks\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.downloads import attempt_download\n",
    "from utils.general import (LOGGER, check_dataset, check_file, check_git_status, check_img_size, check_requirements,\n",
    "                           check_suffix, check_yaml, colorstr, get_latest_run, increment_path, init_seeds,\n",
    "                           intersect_dicts, labels_to_class_weights, labels_to_image_weights, methods, one_cycle,\n",
    "                           print_args, print_mutation, strip_optimizer)\n",
    "from utils.loggers import Loggers\n",
    "from utils.loggers.wandb.wandb_utils import check_wandb_resume\n",
    "from utils.loss import ComputeLoss\n",
    "from utils.metrics import fitness\n",
    "from utils.plots import plot_evolve, plot_labels\n",
    "from utils.torch_utils import EarlyStopping, ModelEMA, de_parallel, select_device, torch_distributed_zero_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 7808ed6 torch 1.10.0+cu102 CUDA:0 (Tesla V100-PCIE-32GB, 32510MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 574 layers, 140057380 parameters, 0 gradients, 208.3 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../dataset/test/0000.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_NAME = 'Inseo_Lee_YOLO'\n",
    "EXPERIMENT_NAME = 'exp2'\n",
    "DATA_ROOT = '../dataset'\n",
    "TEST_DATASET_PATH = os.path.join(DATA_ROOT, 'test')\n",
    "\n",
    "INFERENCE_SIZE = 1024\n",
    "AUGMENT = True\n",
    "\n",
    "\n",
    "IMAGES = []\n",
    "for image_name in os.listdir(TEST_DATASET_PATH):\n",
    "    if not image_name.startswith('._'):\n",
    "        IMAGES.append(os.path.join(TEST_DATASET_PATH, image_name))\n",
    "\n",
    "IMAGES.sort()\n",
    "\n",
    "model = torch.hub.load(\n",
    "    repo_or_dir = './',\n",
    "    model = 'custom',\n",
    "    path = f'../{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt',\n",
    "    source='local')\n",
    "\n",
    "model.conf = 0.001  # NMS confidence threshold\n",
    "model.iou = 0.6  # NMS IoU threshold\n",
    "# model.agnostic = False  # NMS class-agnostic\n",
    "# model.multi_label = False  # NMS multiple labels per box\n",
    "# model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "# model.max_det = 1000  # maximum number of detections per image\n",
    "# model.amp = False  # Automatic Mixed Precision (AMP) inference\n",
    "IMAGES[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4871/4871 [11:03<00:00,  7.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 0.9869502186775208 602.1071166992188 518.241...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 0.9805595278739929 346.0233459472656 250.407...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 0.9810634851455688 776.2323608398438 414.580...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 0.9586802124977112 143.323974609375 261.0804...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.9656744003295898 193.46148681640625 252.17...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  7 0.9869502186775208 602.1071166992188 518.241...  test/0000.jpg\n",
       "1  5 0.9805595278739929 346.0233459472656 250.407...  test/0001.jpg\n",
       "2  1 0.9810634851455688 776.2323608398438 414.580...  test/0002.jpg\n",
       "3  9 0.9586802124977112 143.323974609375 261.0804...  test/0003.jpg\n",
       "4  0 0.9656744003295898 193.46148681640625 252.17...  test/0004.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "for i in tqdm(range(len(IMAGES))):\n",
    "    prediction_string = ''\n",
    "    \n",
    "    output = model(IMAGES[i], size=INFERENCE_SIZE, augment=AUGMENT)\n",
    "    for bbox in output.pandas().xyxy[0].values:\n",
    "        xmin, ymin, xmax, ymax, conf, cls, _ = bbox\n",
    "        prediction_string += f'{cls} {conf} {xmin} {ymin} {xmax} {ymax} '\n",
    "    \n",
    "    path_split = IMAGES[i].split('/')\n",
    "    image_path = f'{path_split[-2]}/{path_split[-1]}'\n",
    "\n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_path)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 0.9911515116691589 602.6592407226562 518.3744506835938 957.2759399414062 1022.9487915039062 7 0.9888994693756104 216.6562042236328 51.11479187011719 456.41973876953125 471.2139892578125 7 0.9844570755958557 447.51336669921875 600.78369140625 647.1171264648438 875.4075927734375 7 0.9827660918235779 119.17108917236328 418.4630126953125 332.15460205078125 712.138916015625 7 0.9764297008514404 650.8900756835938 334.5909423828125 877.3859252929688 601.1932983398438 7 0.9756133556365967 390.62939453125 190.2154083251953 623.306884765625 543.3621215820312 5 0.9587175846099854 243.43389892578125 685.1572875976562 301.1790771484375 748.4664916992188 7 0.956315815448761 547.1837158203125 337.4664306640625 705.528076171875 603.2843627929688 1 0.9525213837623596 567.4407958984375 101.11203002929688 766.6722412109375 358.4510803222656 5 0.9481369256973267 342.8555603027344 643.3126220703125 395.7364196777344 725.853515625 7 0.9452932476997375 238.52243041992188 403.49517822265625 431.5747375488281 579.0050048828125 5 0.8859673142433167 431.97320556640625 457.0985412597656 566.4295043945312 680.0595703125 5 0.841630220413208 395.59906005859375 615.8529052734375 458.7469482421875 689.6356201171875 5 0.6650431156158447 320.94342041015625 667.77490234375 466.0130615234375 746.51123046875 5 0.6357541084289551 385.2710266113281 683.9673461914062 425.8587341308594 721.6345825195312 7 0.6347997188568115 322.02972412109375 566.62255859375 381.7105712890625 619.6513671875 1 0.6229389309883118 430.1856994628906 461.7158203125 571.4422607421875 681.49462890625 5 0.6126810312271118 466.0660400390625 566.2047729492188 565.7398681640625 654.9435424804688 1 0.5927603840827942 463.6031188964844 549.189697265625 570.4863891601562 660.1048583984375 1 0.5594707131385803 633.138671875 165.032470703125 752.2872314453125 338.5815124511719 5 0.4304655194282532 498.0581359863281 598.9835815429688 555.6971435546875 642.8794555664062 5 0.34377172589302063 338.2654113769531 653.8740844726562 419.7702941894531 739.5132446289062 5 0.3287840485572815 346.8583984375 677.243408203125 446.85308837890625 732.248046875 1 0.29030272364616394 467.9029541015625 580.6947631835938 562.2979736328125 651.1198120117188 7 0.2665460705757141 562.8298950195312 602.1505126953125 605.5980834960938 646.224365234375 5 0.223098024725914 373.17034912109375 677.8619995117188 431.4744873046875 725.4363403320312 5 0.20991389453411102 317.3206787109375 603.9083862304688 455.61273193359375 756.1416625976562 5 0.19199353456497192 350.07586669921875 556.5084228515625 471.16790771484375 753.1549072265625 7 0.15536995232105255 316.4886474609375 564.2803955078125 474.73138427734375 757.1712646484375 1 0.14427022635936737 248.62774658203125 425.2950744628906 281.0870361328125 477.8493957519531 5 0.1432759314775467 324.1037902832031 568.6217651367188 383.3523864746094 619.3208618164062 2 0.11441744863986969 329.3662414550781 639.3327026367188 352.4850769042969 683.1880493164062 0 0.1116667240858078 216.50926208496094 692.8555297851562 252.64320373535156 729.9780883789062 5 0.09823528677225113 358.5107727050781 599.1522827148438 420.4871520996094 629.9935913085938 5 0.0942571833729744 393.8140563964844 639.6341552734375 450.7351989746094 705.9375 5 0.08521125465631485 346.1521301269531 683.326904296875 395.5861511230469 726.2652587890625 5 0.08470359444618225 393.418212890625 582.3726806640625 449.8197021484375 689.8450927734375 5 0.08320968598127365 365.4113464355469 562.52685546875 451.6893615722656 718.4671630859375 1 0.0718533918261528 469.41876220703125 552.38134765625 564.3663940429688 600.856689453125 0 0.06807512789964676 243.5264129638672 683.6553955078125 301.52447509765625 747.3966064453125 1 0.05526656657457352 639.4060668945312 185.70452880859375 738.6502075195312 299.7976379394531 5 0.051951270550489426 538.0045776367188 641.083984375 565.2192993164062 651.046142578125 '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(f'../{PROJECT_NAME}/{EXPERIMENT_NAME}', 'submission_exp2_0.01.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pandas()\n",
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_strings = []\n",
    "file_names = []"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "yolov5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
